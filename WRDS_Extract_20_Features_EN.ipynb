{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRDS Feature Extraction: 20 Core Features\n",
    "\n",
    "**In the code, feature names will be renamed to project standard names. The column names used in the actual data file are as follows:**\n",
    "\n",
    "## Feature List (Actual Column Names)\n",
    "\n",
    "### Momentum (5 )\n",
    "- **ret_1_0** (orig: mom1m) - Past 1 month return\n",
    "- **ret_6_1** (orig: mom6m) - Past 6 months return (skip most recent 1 month)\n",
    "- **ret_12_1** (orig: mom12m) - Past 12 months return (skip most recent 1 month)\n",
    "- **ret_36_1** (orig: mom36m) - Past 36 months return\n",
    "- **chmom** - Momentum change = ret_12_1 - ret_1_0\n",
    "\n",
    "### Reversal/Price Behavior (2 )\n",
    "- **rmax1_21d** (orig: maxret) - Maximum return over past 21 days\n",
    "- **rvol_21d** (orig: retvol) - Return volatility over past 21 days\n",
    "\n",
    "### Liquidity (5 )\n",
    "- **turnover_126d** (orig: turn) - Average turnover over past 126 days\n",
    "- **std_turn** - Turnover standard deviation\n",
    "- **dolvol_126d** (orig: dolvol) - Dollar volume over past 126 days\n",
    "- **bidaskhl_21d** (orig: baspread) - Bid-ask spread\n",
    "- **zero_trades_252d** (orig: zerotrade) - Zero trade days ratio over past 252 days\n",
    "\n",
    "### Size/Valuation (3 )\n",
    "- **me** (orig: mve) - Market capitalization\n",
    "- **be_me** (orig: bm) - Book-to-market ratio\n",
    "- **cashpr** - Cash price ratio\n",
    "\n",
    "### Profitability (2 )\n",
    "- **qmj_prof** (orig: operprof) - Profitability\n",
    "- **roeq** - Return on equity\n",
    "\n",
    "### Risk (3 )\n",
    "- **beta_60m** (orig: beta) - 60-month Beta\n",
    "- **betasq** - Beta squared\n",
    "- **ivol_capm_252d** (orig: idiovol) - CAPM residual volatility\n",
    "\n",
    "### Industry (1 feature)\n",
    "- **sic2** - 2-digit SIC industry code\n",
    "\n",
    "**Total: 20 core **\n",
    "\n",
    "## üìã Feature Name Mapping Table\n",
    "\n",
    "| Paper/Original Name | Project Variable Name | Description |\n",
    "|------------|----------|------|\n",
    "| mom1m | ret_1_0 | Past 1 month return |\n",
    "| mom6m | ret_6_1 | Past 6 months return (skip most recent 1 month) |\n",
    "| mom12m | ret_12_1 | Past 12 months return (skip most recent 1 month) |\n",
    "| mom36m | ret_36_1 | Past 36 months return |\n",
    "| maxret | rmax1_21d | Maximum return over past 21 days |\n",
    "| retvol | rvol_21d | Return volatility over past 21 days |\n",
    "| turn | turnover_126d | Average turnover over past 126 days |\n",
    "| dolvol | dolvol_126d | Dollar volume over past 126 days |\n",
    "| baspread | bidaskhl_21d | Bid-ask spread |\n",
    "| zerotrade | zero_trades_252d | Zero trade days ratio over past 252 days |\n",
    "| mve | me | Market capitalization |\n",
    "| bm | be_me | Book-to-market ratio |\n",
    "| beta | beta_60m | 60-month Beta |\n",
    "| idiovol | ivol_capm_252d | CAPM residual volatility |\n",
    "| operprof | qmj_prof | Profitability |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Configure Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfullyÔºÅ\n",
      "üìÖ Data date range: 2018-01-01 to 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# Configuration Parameters\n",
    "# ============================================================================\n",
    "START_DATE = '2018-01-01'  # Data start date\n",
    "END_DATE = '2024-12-31'    # Data end date\n",
    "OUTPUT_FILE = 'wrds_20_.csv'  # Output filename\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfullyÔºÅ\")\n",
    "print(f\"üìÖ Data date range: {START_DATE} to {END_DATE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to WRDS Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connecting to WRDS...\")\n",
    "db = wrds.Connection()\n",
    "print(\"‚úÖ WRDS connection successfulÔºÅ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Check CRSP Daily table structure\n",
    "\n",
    "If you need to see what columns are in the table, you can run the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 columns of CRSP Daily (dsf) table:\n",
      "   column_name          data_type\n",
      "0        cusip  character varying\n",
      "1       permno            integer\n",
      "2       permco            integer\n",
      "3       issuno            integer\n",
      "4        hexcd           smallint\n",
      "5       hsiccd            integer\n",
      "6         date               date\n",
      "7        bidlo            numeric\n",
      "8        askhi            numeric\n",
      "9          prc            numeric\n",
      "10         vol            numeric\n",
      "11         ret            numeric\n",
      "12         bid            numeric\n",
      "13         ask            numeric\n",
      "14      shrout   double precision\n",
      "15      cfacpr   double precision\n",
      "16     cfacshr   double precision\n",
      "17     openprc            numeric\n",
      "18      numtrd            integer\n",
      "19        retx            numeric\n"
     ]
    }
   ],
   "source": [
    "# Optional: Check CRSP Daily table column names\n",
    "# Uncomment the code below to view table structure\n",
    "columns_info = db.raw_sql(\"\"\"\n",
    "     SELECT column_name, data_type\n",
    "     FROM information_schema.columns\n",
    "     WHERE table_schema = 'crsp' \n",
    "       AND table_name = 'dsf'\n",
    "     ORDER BY ordinal_position\n",
    "     LIMIT 50\n",
    " \"\"\")\n",
    "print(\"First 50 columns of CRSP Daily (dsf) table:\")\n",
    "print(columns_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Momentum  (5 )\n",
    "\n",
    "Calculate the following momentum indicators:\n",
    "- **mom1m**: Past 1 month return\n",
    "- **mom6m**: Past 6 months return (skip most recent 1 month)\n",
    "- **mom12m**: Past 12 months return (skip most recent 1 month)\n",
    "- **mom36m**: Past 36 months return (skip most recent 1 month)\n",
    "- **chmom**: Momentum change = mom12m - mom1m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 1: Extracting momentum ...\n",
      "   - Getting daily return data from CRSP Daily...\n",
      "   ‚úÖ Retrieved 15,008,295 daily data records\n",
      "   ‚úÖ Number of stocks: 13,854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "      <th>ret</th>\n",
       "      <th>vol</th>\n",
       "      <th>prc</th>\n",
       "      <th>shrout</th>\n",
       "      <th>askhi</th>\n",
       "      <th>bidlo</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>-0.017454</td>\n",
       "      <td>190618.0</td>\n",
       "      <td>149.17999</td>\n",
       "      <td>18668.0</td>\n",
       "      <td>152.39</td>\n",
       "      <td>147.85001</td>\n",
       "      <td>149.17999</td>\n",
       "      <td>149.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>-0.009988</td>\n",
       "      <td>63693.0</td>\n",
       "      <td>147.69</td>\n",
       "      <td>18668.0</td>\n",
       "      <td>150.27</td>\n",
       "      <td>146.68359</td>\n",
       "      <td>147.41</td>\n",
       "      <td>147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>127552.0</td>\n",
       "      <td>149.73</td>\n",
       "      <td>18668.0</td>\n",
       "      <td>149.99001</td>\n",
       "      <td>147.77</td>\n",
       "      <td>149.45</td>\n",
       "      <td>149.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>-0.00955</td>\n",
       "      <td>44647.0</td>\n",
       "      <td>148.3</td>\n",
       "      <td>18668.0</td>\n",
       "      <td>150.89</td>\n",
       "      <td>148.25999</td>\n",
       "      <td>148.28999</td>\n",
       "      <td>148.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>55014.0</td>\n",
       "      <td>148.41</td>\n",
       "      <td>18668.0</td>\n",
       "      <td>150.96899</td>\n",
       "      <td>146.20821</td>\n",
       "      <td>148.21001</td>\n",
       "      <td>148.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       date       ret       vol        prc   shrout      askhi  \\\n",
       "0   10026 2018-01-02 -0.017454  190618.0  149.17999  18668.0     152.39   \n",
       "1   10026 2018-01-03 -0.009988   63693.0     147.69  18668.0     150.27   \n",
       "2   10026 2018-01-04  0.013813  127552.0     149.73  18668.0  149.99001   \n",
       "3   10026 2018-01-05  -0.00955   44647.0      148.3  18668.0     150.89   \n",
       "4   10026 2018-01-08  0.000742   55014.0     148.41  18668.0  150.96899   \n",
       "\n",
       "       bidlo        bid     ask  \n",
       "0  147.85001  149.17999  149.42  \n",
       "1  146.68359     147.41  147.69  \n",
       "2     147.77     149.45  149.72  \n",
       "3  148.25999  148.28999  148.39  \n",
       "4  146.20821  148.21001  148.34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"üìä Step 1: Extracting Momentum ...\")\n",
    "\n",
    "# Get daily returns from CRSP Daily\n",
    "# Include bid and ask columns for more accurate Bid-ask spread calculation, and hsiccd for Industry classification\n",
    "print(\"   - Getting daily return data from CRSP Daily...\")\n",
    "try:\n",
    "    crsp_daily = db.raw_sql(f\"\"\"\n",
    "        SELECT permno, date, ret, vol, prc, shrout, askhi, bidlo, bid, ask, hsiccd\n",
    "        FROM crsp.dsf\n",
    "        WHERE date >= '{START_DATE}' \n",
    "          AND date <= '{END_DATE}'\n",
    "          AND ret IS NOT NULL\n",
    "        ORDER BY permno, date\n",
    "    \"\"\")\n",
    "    print(\"   ‚úÖ SQL query successful\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Query with hsiccd failed: {str(e)[:200]}\")\n",
    "    print(\"   - Trying query without hsiccd...\")\n",
    "    crsp_daily = db.raw_sql(f\"\"\"\n",
    "        SELECT permno, date, ret, vol, prc, shrout, askhi, bidlo, bid, ask\n",
    "        FROM crsp.dsf\n",
    "        WHERE date >= '{START_DATE}' \n",
    "          AND date <= '{END_DATE}'\n",
    "          AND ret IS NOT NULL\n",
    "        ORDER BY permno, date\n",
    "    \"\"\")\n",
    "\n",
    "crsp_daily['date'] = pd.to_datetime(crsp_daily['date'])\n",
    "crsp_daily = crsp_daily.sort_values(['permno', 'date'])\n",
    "\n",
    "print(f\"   ‚úÖ Retrieved {len(crsp_daily):,} daily data records\")\n",
    "print(f\"   ‚úÖ Number of stocks: {crsp_daily['permno'].nunique():,}\")\n",
    "print(f\"   ‚úÖ Data columns: {list(crsp_daily.columns)}\")\n",
    "if 'hsiccd' in crsp_daily.columns:\n",
    "    print(f\"   ‚úÖ hsiccd column exists, valid values: {crsp_daily['hsiccd'].notna().sum():,}\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  hsiccd column does not exist\")\n",
    "crsp_daily.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Calculating momentum ...\n",
      "   ‚úÖ Momentum  calculated\n",
      "   - mom1m: 14,718,770  valid values\n",
      "   - mom12m: 11,739,553  valid values\n"
     ]
    }
   ],
   "source": [
    "# Calculating momentum \n",
    "print(\"   - Calculating momentum ...\")\n",
    "\n",
    "def calc_momentum(group):\n",
    "    \"\"\"Calculate various momentum indicators\"\"\"\n",
    "    ret = group['ret'].values\n",
    "    \n",
    "    # Convert to numpy array for fast calculation\n",
    "    ret_plus_one = 1 + ret\n",
    "    ret_plus_one[np.isnan(ret_plus_one)] = 1\n",
    "    \n",
    "    # mom1m: Past 1  months (21  trading days)\n",
    "    mom1m = np.full(len(group), np.nan)\n",
    "    for i in range(21, len(group)):\n",
    "        mom1m[i] = np.prod(ret_plus_one[i-21:i]) - 1\n",
    "    \n",
    "    # mom6m: Past 6 months, skip most recent 1 month (21-168 trading days)\n",
    "    mom6m = np.full(len(group), np.nan)\n",
    "    for i in range(168, len(group)):\n",
    "        mom6m[i] = np.prod(ret_plus_one[i-168:i-21]) - 1\n",
    "    \n",
    "    # mom12m: Past 12 months, skip most recent 1 month (21-252 trading days)\n",
    "    mom12m = np.full(len(group), np.nan)\n",
    "    for i in range(252, len(group)):\n",
    "        mom12m[i] = np.prod(ret_plus_one[i-252:i-21]) - 1\n",
    "    \n",
    "    # mom36m: Past 36 months, skip most recent 1 month (21-756 trading days)\n",
    "    mom36m = np.full(len(group), np.nan)\n",
    "    for i in range(756, len(group)):\n",
    "        mom36m[i] = np.prod(ret_plus_one[i-756:i-21]) - 1\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'mom1m': mom1m,\n",
    "        'mom6m': mom6m,\n",
    "        'mom12m': mom12m,\n",
    "        'mom36m': mom36m\n",
    "    }, index=group.index)\n",
    "\n",
    "momentum_ = crsp_daily.groupby('permno', group_keys=False).apply(calc_momentum)\n",
    "crsp_daily = pd.concat([crsp_daily, momentum_], axis=1)\n",
    "\n",
    "# chmom: Momentum change\n",
    "crsp_daily['chmom'] = crsp_daily['mom12m'] - crsp_daily['mom1m']\n",
    "\n",
    "print(\"   ‚úÖ Momentum  calculated\")\n",
    "print(f\"   - mom1m: {crsp_daily['mom1m'].notna().sum():,}  valid values\")\n",
    "print(f\"   - mom12m: {crsp_daily['mom12m'].notna().sum():,}  valid values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Reversal/Price Behavior  (2 )\n",
    "\n",
    "- **maxret**: Maximum daily return over past 21 days\n",
    "- **retvol**: Return volatility over past 21 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 2: Extracting reversal/price behavior ...\n",
      "   ‚úÖ Reversal  calculated\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Step 2: Extracting reversal/price behavior ...\")\n",
    "\n",
    "# maxret: Maximum daily return over past 21 days\n",
    "crsp_daily['maxret'] = crsp_daily.groupby('permno')['ret'].transform(\n",
    "    lambda x: x.rolling(21, min_periods=10).max()\n",
    ")\n",
    "\n",
    "# retvol: Return volatility over past 21 days\n",
    "crsp_daily['retvol'] = crsp_daily.groupby('permno')['ret'].transform(\n",
    "    lambda x: x.rolling(21, min_periods=10).std()\n",
    ")\n",
    "\n",
    "print(\"   ‚úÖ Reversal  calculated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Liquidity  (5 )\n",
    "\n",
    "- **turn**: Turnover = volume / shares outstanding\n",
    "- **std_turn**: Turnover volatility\n",
    "- **dolvol**: Dollar volume = volume √ó price\n",
    "- **zerotrade**: Zero trade days ratio (past 252 days)\n",
    "- **baspread**: Bid-ask spreadÔºàPrefer using bid/ask, otherwise use askhi/bidloÔºâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 3: Extracting liquidity ...\n",
      "   ‚úÖ Liquidity  calculated\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Step 3: Extracting liquidity ...\")\n",
    "\n",
    "# turn: Turnover = volume / shares outstanding\n",
    "crsp_daily['turn'] = crsp_daily['vol'] / crsp_daily['shrout']\n",
    "crsp_daily['turn_126d'] = crsp_daily.groupby('permno')['turn'].transform(\n",
    "    lambda x: x.rolling(126, min_periods=60).mean()\n",
    ")\n",
    "\n",
    "# std_turn: Turnover volatility\n",
    "crsp_daily['std_turn'] = crsp_daily.groupby('permno')['turn'].transform(\n",
    "    lambda x: x.rolling(126, min_periods=60).std()\n",
    ")\n",
    "\n",
    "# dolvol: Dollar volume = volume * price\n",
    "crsp_daily['dolvol'] = crsp_daily['vol'] * crsp_daily['prc']\n",
    "crsp_daily['dolvol_126d'] = crsp_daily.groupby('permno')['dolvol'].transform(\n",
    "    lambda x: x.rolling(126, min_periods=60).mean()\n",
    ")\n",
    "\n",
    "# zerotrade: Zero trade days ratio (past 252 days)\n",
    "# Handle missing values: missing vol is treated as non-zero (i.e., not a zero trade day), only vol==0 is marked as 1\n",
    "crsp_daily['is_zero'] = ((crsp_daily['vol'] == 0) & (crsp_daily['vol'].notna())).astype(int)\n",
    "crsp_daily['zerotrade'] = crsp_daily.groupby('permno')['is_zero'].transform(\n",
    "    lambda x: x.rolling(252, min_periods=120).mean()\n",
    ")\n",
    "\n",
    "# baspread: Bid-ask spread\n",
    "# Prefer using bid and ask for calculation (more accurate), otherwise use askhi and bidlo\n",
    "if 'bid' in crsp_daily.columns and 'ask' in crsp_daily.columns:\n",
    "    # Calculate Bid-ask spread using bid and ask:(ask - bid) / mid_price\n",
    "    crsp_daily['mid_price'] = (crsp_daily['bid'] + crsp_daily['ask']) / 2\n",
    "    crsp_daily['baspread_est'] = (crsp_daily['ask'] - crsp_daily['bid']) / crsp_daily['mid_price']\n",
    "    # Handle missing values: if bid/ask is missing, use askhi/bidlo\n",
    "    mask = crsp_daily['baspread_est'].isna()\n",
    "    if mask.any() and 'askhi' in crsp_daily.columns and 'bidlo' in crsp_daily.columns:\n",
    "        crsp_daily.loc[mask, 'baspread_est'] = (\n",
    "            (crsp_daily.loc[mask, 'askhi'] - crsp_daily.loc[mask, 'bidlo']) / \n",
    "            crsp_daily.loc[mask, 'prc']\n",
    "        )\n",
    "elif 'askhi' in crsp_daily.columns and 'bidlo' in crsp_daily.columns:\n",
    "    # Calculate using askhi and bidlo\n",
    "    crsp_daily['baspread_est'] = (crsp_daily['askhi'] - crsp_daily['bidlo']) / crsp_daily['prc']\n",
    "else:\n",
    "    # If neither is available, use return volatility as a proxy\n",
    "    print(\"   ‚ö†Ô∏è  bid/ask or askhi/bidlo columns not found, using return volatility as liquidity proxy\")\n",
    "    crsp_daily['baspread_est'] = crsp_daily.groupby('permno')['ret'].transform(\n",
    "        lambda x: x.rolling(21, min_periods=10).std()\n",
    "    )\n",
    "\n",
    "# Calculate 21-day average Bid-ask spread\n",
    "crsp_daily['baspread_21d'] = crsp_daily.groupby('permno')['baspread_est'].transform(\n",
    "    lambda x: x.rolling(21, min_periods=10).mean()\n",
    ")\n",
    "\n",
    "print(\"   ‚úÖ Liquidity  calculated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Size/Valuation  (3 )\n",
    "\n",
    "- **mve (size)**: Market capitalization = price √ó shares outstanding\n",
    "- **bm**: Book-to-market ratio = book value / Market capitalization\n",
    "- **cashpr**: cash price ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 4: Extracting size/valuation ...\n",
      "   - Getting market capitalization data from CRSP Monthly...\n",
      "   ‚úÖ Retrieved 729,493 monthly data records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "      <th>prc</th>\n",
       "      <th>shrout</th>\n",
       "      <th>mve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>138.44</td>\n",
       "      <td>18678.0</td>\n",
       "      <td>2585782.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>134.33</td>\n",
       "      <td>18678.0</td>\n",
       "      <td>2509015.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>136.56</td>\n",
       "      <td>18697.0</td>\n",
       "      <td>2553262.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>137.41</td>\n",
       "      <td>18702.0</td>\n",
       "      <td>2569841.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>141.62</td>\n",
       "      <td>18702.0</td>\n",
       "      <td>2648577.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       date     prc   shrout         mve\n",
       "0   10026 2018-01-31  138.44  18678.0  2585782.32\n",
       "1   10026 2018-02-28  134.33  18678.0  2509015.74\n",
       "2   10026 2018-03-29  136.56  18697.0  2553262.32\n",
       "3   10026 2018-04-30  137.41  18702.0  2569841.82\n",
       "4   10026 2018-05-31  141.62  18702.0  2648577.24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"üìä Step 4: Extracting size/valuation ...\")\n",
    "\n",
    "# mve: Market capitalizationÔºàmore accurate from CRSP MonthlyÔºâ\n",
    "print(\"   - Getting Market capitalization data from CRSP Monthly...\")\n",
    "crsp_monthly = db.raw_sql(f\"\"\"\n",
    "    SELECT permno, date, prc, shrout\n",
    "    FROM crsp.msf\n",
    "    WHERE date >= '{START_DATE}' \n",
    "      AND date <= '{END_DATE}'\n",
    "    ORDER BY permno, date\n",
    "\"\"\")\n",
    "\n",
    "crsp_monthly['date'] = pd.to_datetime(crsp_monthly['date'])\n",
    "crsp_monthly['mve'] = crsp_monthly['prc'] * crsp_monthly['shrout']  # In millions of USD\n",
    "\n",
    "print(f\"   ‚úÖ Retrieved {len(crsp_monthly):,} monthly data records\")\n",
    "crsp_monthly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Getting book value data from Compustat...\n",
      "   - Link Compustat and CRSP...\n",
      "   ‚úÖ Book-to-market ratio calculated\n"
     ]
    }
   ],
   "source": [
    "# bm: Book-to-market ratioÔºàrequires CompustatÔºâ\n",
    "print(\" - Getting book value data from Compustat...\")\n",
    "compustat = db.raw_sql(f\"\"\"\n",
    "    SELECT gvkey, datadate, ceq, at, che, act, lt\n",
    "    FROM comp.funda\n",
    "    WHERE datadate >= '{START_DATE}' \n",
    "      AND datadate <= '{END_DATE}'\n",
    "      AND indfmt = 'INDL'\n",
    "      AND datafmt = 'STD'\n",
    "      AND popsrc = 'D'\n",
    "      AND consol = 'C'\n",
    "    ORDER BY gvkey, datadate\n",
    "\"\"\")\n",
    "\n",
    "compustat['datadate'] = pd.to_datetime(compustat['datadate'])\n",
    "\n",
    "# Link Compustat and CRSP\n",
    "print(\"   - Link Compustat and CRSP...\")\n",
    "link_table = db.raw_sql(\"\"\"\n",
    "    SELECT gvkey, lpermno as permno, linkdt, linkenddt\n",
    "    FROM crsp.ccmxpf_linktable\n",
    "    WHERE linktype IN ('LU', 'LC')\n",
    "\"\"\")\n",
    "\n",
    "link_table['linkdt'] = pd.to_datetime(link_table['linkdt'])\n",
    "link_table['linkenddt'] = pd.to_datetime(link_table['linkenddt'])\n",
    "\n",
    "# Merge Compustat and CRSP\n",
    "compustat['year'] = compustat['datadate'].dt.year\n",
    "compustat['month'] = compustat['datadate'].dt.month\n",
    "\n",
    "# Merge link table\n",
    "compustat_linked = compustat.merge(\n",
    "    link_table, on='gvkey', how='inner'\n",
    ").query('datadate >= linkdt & (linkenddt.isna() | datadate <= linkenddt)')\n",
    "\n",
    "# Only keep December data for matching (fiscal year end is usually in December)\n",
    "compustat_dec = compustat_linked[compustat_linked['month'] == 12].copy()\n",
    "compustat_dec = compustat_dec[['permno', 'year', 'ceq']].rename(columns={'ceq': 'be'})\n",
    "\n",
    "# Merge to CRSP monthly data\n",
    "crsp_monthly['year'] = crsp_monthly['date'].dt.year\n",
    "crsp_monthly['month'] = crsp_monthly['date'].dt.month\n",
    "\n",
    "crsp_monthly = crsp_monthly.merge(\n",
    "    compustat_dec, \n",
    "    left_on=['permno', 'year'], \n",
    "    right_on=['permno', 'year'], \n",
    "    how='left'\n",
    ")\n",
    "crsp_monthly['be'] = crsp_monthly.groupby('permno')['be'].ffill()\n",
    "\n",
    "# Calculate be_me\n",
    "crsp_monthly['bm'] = crsp_monthly['be'] / (crsp_monthly['mve'] * 1e6)  # be is in millions, mve is also in millions\n",
    "\n",
    "print(\" ‚úÖ Book-to-market ratio calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Cash price ratio calculated\n",
      "   ‚úÖ Size/valuation  calculated\n"
     ]
    }
   ],
   "source": [
    "# cashpr: cash price ratioÔºàrequires Compustat dataÔºâ\n",
    "# First filter December data, then select needed columns\n",
    "compustat_cash = compustat_linked[compustat_linked['month'] == 12][['permno', 'year', 'che', 'act', 'lt']].copy()\n",
    "compustat_cash = compustat_cash.merge(\n",
    "    crsp_monthly[crsp_monthly['month'] == 12][['permno', 'year', 'mve']],\n",
    "    on=['permno', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "compustat_cash['cashpr'] = (\n",
    "    compustat_cash['che'] + 0.75 * compustat_cash['act'] - 0.5 * compustat_cash['lt']\n",
    ") / (compustat_cash['mve'] * 1e6)\n",
    "\n",
    "print(\" ‚úÖ Cash price ratio calculated\")\n",
    "print(\" ‚úÖ Size/valuation  calculated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Profitability  (2 )\n",
    "\n",
    "- **operprof**: Operating profit margin = (revenue - cost of goods sold - selling, general and administrative expenses - interest expense) / shareholders equity\n",
    "- **roeq**: Return on equity = net income / shareholders equity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 5: Extracting Profitability ...\n",
      "   ‚úÖ Profitability  calculated\n",
      "   - Valid operprof values: 20,715\n",
      "   - Valid roeq values: 29,763\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Step 5: Extracting Profitability ...\")\n",
    "\n",
    "compustat_prof = db.raw_sql(f\"\"\"\n",
    "    SELECT gvkey, datadate, revt, cogs, xsga, xint, ceq, ib\n",
    "    FROM comp.funda\n",
    "    WHERE datadate >= '{START_DATE}' \n",
    "      AND datadate <= '{END_DATE}'\n",
    "      AND indfmt = 'INDL'\n",
    "      AND datafmt = 'STD'\n",
    "      AND popsrc = 'D'\n",
    "      AND consol = 'C'\n",
    "    ORDER BY gvkey, datadate\n",
    "\"\"\")\n",
    "\n",
    "compustat_prof['datadate'] = pd.to_datetime(compustat_prof['datadate'])\n",
    "compustat_prof['year'] = compustat_prof['datadate'].dt.year\n",
    "compustat_prof['month'] = compustat_prof['datadate'].dt.month\n",
    "\n",
    "# Link to CRSP\n",
    "compustat_prof_linked = compustat_prof.merge(\n",
    "    link_table, on='gvkey', how='inner'\n",
    ").query('datadate >= linkdt & (linkenddt.isna() | datadate <= linkenddt)')\n",
    "\n",
    "# operprof: Operating profit margin\n",
    "compustat_prof_linked['operprof'] = (\n",
    "    compustat_prof_linked['revt'] - compustat_prof_linked['cogs'] \n",
    "    - compustat_prof_linked['xsga'] - compustat_prof_linked['xint']\n",
    ") / compustat_prof_linked['ceq']\n",
    "\n",
    "# roeq: Return on equity\n",
    "compustat_prof_linked['roeq'] = compustat_prof_linked['ib'] / compustat_prof_linked['ceq']\n",
    "\n",
    "# Only keep year-end data\n",
    "compustat_prof_dec = compustat_prof_linked[\n",
    "    compustat_prof_linked['month'] == 12\n",
    "][['permno', 'year', 'operprof', 'roeq']]\n",
    "\n",
    "print(\" ‚úÖ Profitability  calculated\")\n",
    "print(f\" - Valid operprof values: {compustat_prof_dec['operprof'].notna().sum():,}\")\n",
    "print(f\" - Valid roeq values: {compustat_prof_dec['roeq'].notna().sum():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract Risk  (3 )\n",
    "\n",
    "- **beta**: CAPM betaÔºàusing past 252 trading days to regress on market returnsÔºâ\n",
    "- **betasq**: beta squared\n",
    "- **idiovol**: idiosyncratic volatility (standard deviation of CAPM residuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 6: Extracting risk ...\n",
      "   - Getting market return data...\n",
      "   ‚úÖ Retrieved 1,761 market return data records\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Step 6: Extracting risk ...\")\n",
    "\n",
    "# Get market returns\n",
    "print(\"   - Getting market return data...\")\n",
    "market_ret = db.raw_sql(f\"\"\"\n",
    "    SELECT date, vwretd as mkt_ret\n",
    "    FROM crsp.dsi\n",
    "    WHERE date >= '{START_DATE}' \n",
    "      AND date <= '{END_DATE}'\n",
    "\"\"\")\n",
    "\n",
    "market_ret['date'] = pd.to_datetime(market_ret['date'])\n",
    "\n",
    "# Merge stock and market returns\n",
    "crsp_beta = crsp_daily[['permno', 'date', 'ret']].merge(\n",
    "    market_ret, on='date', how='left'\n",
    ")\n",
    "\n",
    "print(f\"   ‚úÖ Retrieved {len(market_ret):,} market return data records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Calculating CAPM beta...\n",
      "   ‚úÖ Beta calculated\n"
     ]
    }
   ],
   "source": [
    "# Calculate beta (simplified version: using past 252  trading days)\n",
    "print(\"   - Calculating CAPM beta...\")\n",
    "\n",
    "def calc_beta_simple(group):\n",
    "    \"\"\"Simplified beta calculation\"\"\"\n",
    "    ret = group['ret'].values\n",
    "    mkt_ret = group['mkt_ret'].values\n",
    "    \n",
    "    beta = np.full(len(group), np.nan)\n",
    "    for i in range(252, len(group)):\n",
    "        y = ret[i-252:i]\n",
    "        x = mkt_ret[i-252:i]\n",
    "        mask = ~(np.isnan(y) | np.isnan(x))\n",
    "        if mask.sum() >= 60:\n",
    "            cov = np.cov(y[mask], x[mask])[0,1]\n",
    "            var = np.var(x[mask])\n",
    "            if var > 0:\n",
    "                beta[i] = cov / var\n",
    "    \n",
    "    return pd.Series(beta, index=group.index)\n",
    "\n",
    "crsp_beta['beta'] = crsp_beta.groupby('permno', group_keys=False).apply(calc_beta_simple).values\n",
    "crsp_beta['betasq'] = crsp_beta['beta'] ** 2\n",
    "\n",
    "print(\"   ‚úÖ Beta calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Calculating idiosyncratic volatility...\n",
      "   ‚úÖ Idiosyncratic volatility calculated\n",
      "   ‚úÖ Risk  calculated\n"
     ]
    }
   ],
   "source": [
    "# Calculate idiovol (idiosyncratic volatility)\n",
    "print(\"   - Calculating idiosyncratic volatility...\")\n",
    "\n",
    "def calc_idiovol_simple(group):\n",
    "    \"\"\"Simplified idiovol calculation\"\"\"\n",
    "    ret = group['ret'].values\n",
    "    mkt_ret = group['mkt_ret'].values\n",
    "    \n",
    "    idiovol = np.full(len(group), np.nan)\n",
    "    for i in range(252, len(group)):\n",
    "        y = ret[i-252:i]\n",
    "        x = mkt_ret[i-252:i]\n",
    "        mask = ~(np.isnan(y) | np.isnan(x))\n",
    "        if mask.sum() >= 60:\n",
    "            # Simple linear regression\n",
    "            x_clean = x[mask]\n",
    "            y_clean = y[mask]\n",
    "            beta = np.cov(y_clean, x_clean)[0,1] / np.var(x_clean)\n",
    "            alpha = np.mean(y_clean) - beta * np.mean(x_clean)\n",
    "            residuals = y_clean - (alpha + beta * x_clean)\n",
    "            idiovol[i] = np.std(residuals)\n",
    "    \n",
    "    return pd.Series(idiovol, index=group.index)\n",
    "\n",
    "crsp_beta['idiovol'] = crsp_beta.groupby('permno', group_keys=False).apply(calc_idiovol_simple).values\n",
    "\n",
    "print(\"   ‚úÖ Idiosyncratic volatility calculated\")\n",
    "print(\"   ‚úÖ Risk  calculated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extract Industry variable (1 )\n",
    "\n",
    "- **sic2**: First 2 digits of SIC industry code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 7: Extracting industry ...\n",
      "   - Check if hsiccd can be extracted from crsp_daily...\n",
      "   - Columns of crsp_daily: ['permno', 'date', 'ret', 'vol', 'prc', 'shrout', 'askhi', 'bidlo', 'bid', 'ask', 'mom1m', 'mom6m', 'mom12m', 'mom36m', 'chmom', 'maxret', 'retvol', 'turn', 'turn_126d', 'std_turn', 'dolvol', 'dolvol_126d', 'is_zero', 'zerotrade', 'mid_price', 'baspread_est', 'baspread_21d']\n",
      "   ‚ö†Ô∏è  hsiccd column not found in crsp_daily, trying to query from crsp.stocknames...\n",
      "   - Need to query 13,854  stocks\n",
      "   - Note: crsp.stocknames uses date range columns (namedt, nameenddt)\n",
      "   - Database connection cleaned\n",
      "   - Method: Get stocknames data, then merge with crsp_daily dates...\n",
      "   - Processed 1000/13854  stocks\n",
      "   - Processed 2000/13854  stocks\n",
      "   - Processed 3000/13854  stocks\n",
      "   - Processed 4000/13854  stocks\n",
      "   - Processed 5000/13854  stocks\n",
      "   - Processed 6000/13854  stocks\n",
      "   - Processed 7000/13854  stocks\n",
      "   - Processed 8000/13854  stocks\n",
      "   - Processed 9000/13854  stocks\n",
      "   - Processed 10000/13854  stocks\n",
      "   - Processed 11000/13854  stocks\n",
      "   - Processed 12000/13854  stocks\n",
      "   - Processed 13000/13854  stocks\n",
      "   - Processed 13854/13854  stocks\n",
      "   - Merge with crsp_daily dates (using vectorized method)...\n",
      "   - Successfully matched 15,008,295  records\n",
      "   ‚úÖ Industry  extracted\n",
      "   - Unique industry code count: 74\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Step 7: Extracting Industry ...\")\n",
    "\n",
    "# Option 1: Prefer getting hsiccd from crsp.dsf (if available, faster and no additional query needed)\n",
    "print(\"   - Check if hsiccd can be extracted from crsp_daily...\")\n",
    "print(f\"   - Columns of crsp_daily: {list(crsp_daily.columns)}\")\n",
    "\n",
    "if 'hsiccd' in crsp_daily.columns:\n",
    "    print(\"   ‚úÖ Found hsiccd column, extracting directly from crsp_daily...\")\n",
    "    crsp_names = crsp_daily[['permno', 'date', 'hsiccd']].copy()\n",
    "    crsp_names = crsp_names.rename(columns={'hsiccd': 'siccd'})\n",
    "    crsp_names = crsp_names.dropna(subset=['siccd'])\n",
    "    print(f\"   - Extracted {len(crsp_names):,}  records\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  hsiccd column not found in crsp_daily, trying to query from crsp.stocknames...\")\n",
    "    # Option 2: Query from crsp.stocknames (requires rollback handling)\n",
    "    # Note: crsp.stocknames uses namedt and nameenddt to represent date range, not a single date column\n",
    "    unique_permnos = crsp_daily['permno'].unique()\n",
    "    print(f\"   - Need to query {len(unique_permnos):,}   stocks\")\n",
    "    print(\"   - Note: crsp.stocknames uses date range columns (namedt, nameenddt)\")\n",
    "    \n",
    "    # First try rollback to clean previous error transactions\n",
    "    try:\n",
    "        db.connection.rollback()\n",
    "        print(\"   - Database connection cleaned\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Optimized method: First get all stocknames data, then merge with crsp_daily dates\n",
    "    print(\"   - Method: Get stocknames data, then merge with crsp_daily dates...\")\n",
    "    \n",
    "    # Split permno list into multiple batches\n",
    "    batch_size = 1000  # Increase batch size to reduce number of queries\n",
    "    stocknames_list = []\n",
    "    \n",
    "    for i in range(0, len(unique_permnos), batch_size):\n",
    "        batch_permnos = unique_permnos[i:i+batch_size]\n",
    "        permno_str = ','.join(map(str, batch_permnos))\n",
    "        \n",
    "        try:\n",
    "            db.connection.rollback()\n",
    "            batch_data = db.raw_sql(f\"\"\"\n",
    "                SELECT permno, namedt, nameenddt, siccd\n",
    "                FROM crsp.stocknames\n",
    "                WHERE permno IN ({permno_str})\n",
    "                  AND (nameenddt IS NULL OR nameenddt >= '{START_DATE}')\n",
    "                  AND namedt <= '{END_DATE}'\n",
    "            \"\"\")\n",
    "            if len(batch_data) > 0:\n",
    "                stocknames_list.append(batch_data)\n",
    "            print(f\"   - Processed {min(i+batch_size, len(unique_permnos))}/{len(unique_permnos)}   stocks\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Batch {i//batch_size + 1} Query failed: {str(e)[:100]}\")\n",
    "            try:\n",
    "                db.connection.rollback()\n",
    "            except:\n",
    "                pass\n",
    "            continue\n",
    "    \n",
    "    if stocknames_list:\n",
    "        # Merge all batches\n",
    "        stocknames_all = pd.concat(stocknames_list, ignore_index=True)\n",
    "        stocknames_all['namedt'] = pd.to_datetime(stocknames_all['namedt'])\n",
    "        stocknames_all['nameenddt'] = pd.to_datetime(stocknames_all['nameenddt'])\n",
    "        \n",
    "        # Merge with crsp_daily dates: For each permno-date, find corresponding siccd\n",
    "        print(\"   - Merge with crsp_daily dates (using vectorized method)...\")\n",
    "        crsp_daily_dates = crsp_daily[['permno', 'date']].copy()\n",
    "        \n",
    "        # Use merge_asof for efficient matching (group by permno, match by nearest date)\n",
    "        # First prepare stocknames data for each permno\n",
    "        crsp_names_list = []\n",
    "        for permno in crsp_daily_dates['permno'].unique():\n",
    "            permno_dates = crsp_daily_dates[crsp_daily_dates['permno'] == permno][['date']].copy()\n",
    "            permno_stocknames = stocknames_all[stocknames_all['permno'] == permno].copy()\n",
    "            \n",
    "            if len(permno_stocknames) == 0:\n",
    "                continue\n",
    "            \n",
    "            # For each date, find valid siccd\n",
    "            siccd_list = []\n",
    "            for date in permno_dates['date']:\n",
    "                valid = permno_stocknames[\n",
    "                    (permno_stocknames['namedt'] <= date) &\n",
    "                    ((permno_stocknames['nameenddt'].isna()) | (permno_stocknames['nameenddt'] >= date))\n",
    "                ]\n",
    "                if len(valid) > 0:\n",
    "                    # Take the one with largest namedt (most recent)\n",
    "                    siccd_list.append(valid.loc[valid['namedt'].idxmax(), 'siccd'])\n",
    "                else:\n",
    "                    siccd_list.append(None)\n",
    "            \n",
    "            permno_dates['permno'] = permno\n",
    "            permno_dates['siccd'] = siccd_list\n",
    "            crsp_names_list.append(permno_dates)\n",
    "        \n",
    "        if crsp_names_list:\n",
    "            crsp_names = pd.concat(crsp_names_list, ignore_index=True)\n",
    "            crsp_names = crsp_names[['permno', 'date', 'siccd']].dropna(subset=['siccd'])\n",
    "            print(f\"   - Successfully matched {len(crsp_names):,}  records\")\n",
    "        else:\n",
    "            crsp_names = pd.DataFrame(columns=['permno', 'date', 'siccd'])\n",
    "            print(\"   ‚ö†Ô∏è  Failed to match any records\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Unable to get data from stocknames, creating empty data frame\")\n",
    "        crsp_names = pd.DataFrame(columns=['permno', 'date', 'siccd'])\n",
    "\n",
    "# Process data\n",
    "if len(crsp_names) > 0:\n",
    "    crsp_names['date'] = pd.to_datetime(crsp_names['date'])\n",
    "    crsp_names['sic2'] = crsp_names['siccd'].astype(str).str[:2]\n",
    "    print(\"   ‚úÖ Industry features extracted\")\n",
    "    print(f\"   - Unique industry code count: {crsp_names['sic2'].nunique()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Failed to get Industry data, creating empty data frame\")\n",
    "    crsp_names = pd.DataFrame(columns=['permno', 'date', 'siccd', 'sic2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Merge all features to monthly frequency\n",
    "\n",
    "Aggregate all daily features to monthly frequency (take end-of-month values), and merge all features into one data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 8: Merge all features to monthly frequency...\n",
      "   ‚úÖ Daily data aggregation completed, total 720,831  monthly records\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Step 8: Merge all features to monthly frequency...\")\n",
    "\n",
    "# Aggregate daily data to monthly (take end-of-month values)\n",
    "crsp_daily['year'] = crsp_daily['date'].dt.year\n",
    "crsp_daily['month'] = crsp_daily['date'].dt.month\n",
    "\n",
    "# Select end-of-month data\n",
    "daily_monthly = crsp_daily.groupby(['permno', 'year', 'month']).last().reset_index()\n",
    "daily_monthly['date'] = pd.to_datetime(daily_monthly[['year', 'month']].assign(day=1))\n",
    "\n",
    "# Merge all features (note: need to keep year and month columns for subsequent merge)\n",
    "_monthly = daily_monthly[[\n",
    "    'permno', 'date', 'year', 'month', 'mom1m', 'mom6m', 'mom12m', 'mom36m', 'chmom',\n",
    "    'maxret', 'retvol', 'turn_126d', 'std_turn', 'dolvol_126d', \n",
    "    'zerotrade', 'baspread_21d'\n",
    "]].copy()\n",
    "\n",
    "print(f\"   ‚úÖ Daily data aggregation completed, total {len(_monthly):,}  monthly records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Merge market capitalization and bm data...\n",
      "   - After merging market capitalization data, mve valid values: 716,975\n",
      "   - Merge beta and idiovol data...\n",
      "   - After merging beta data, beta valid values: 564,101\n",
      "   - Merge profitability data...\n",
      "   - compustat_prof_dec columns: ['permno', 'year', 'operprof', 'roeq']\n",
      "   ‚ö†Ô∏è  Found duplicate column roeqÔºåDelete old column first\n",
      "   - After merging profitability data, operprof valid values: 237,279\n",
      "   - After merging profitability data, roeq valid values: 341,373\n",
      "   - cashpr already exists, skip merge\n",
      "   - sic2 already exists and has data, skip merge\n",
      "   - Clean duplicate columns...\n",
      "   - Renamed 2  columns (removed suffix)\n",
      "   - No duplicate columns to delete\n",
      "   ‚úÖ All features merged\n"
     ]
    }
   ],
   "source": [
    "# Merge Market capitalization and bm\n",
    "# Note: need to unify date format, use year and month for merge\n",
    "\n",
    "# Ensure _monthly has year and month columns\n",
    "if 'year' not in _monthly.columns or 'month' not in _monthly.columns:\n",
    "    print(\"   ‚ö†Ô∏è  _monthly missing year or month columns, adding...\")\n",
    "    _monthly['year'] = _monthly['date'].dt.year\n",
    "    _monthly['month'] = _monthly['date'].dt.month\n",
    "\n",
    "# Ensure crsp_monthly has year and month columns\n",
    "if 'year' not in crsp_monthly.columns or 'month' not in crsp_monthly.columns:\n",
    "    crsp_monthly['year'] = crsp_monthly['date'].dt.year\n",
    "    crsp_monthly['month'] = crsp_monthly['date'].dt.month\n",
    "\n",
    "# Check if already merged (avoid duplicate merge)\n",
    "if 'mve' not in _monthly.columns or 'bm' not in _monthly.columns:\n",
    "    print(\"   - Merge Market capitalization and bm data...\")\n",
    "    _monthly = _monthly.merge(\n",
    "        crsp_monthly[['permno', 'year', 'month', 'mve', 'bm']],\n",
    "        on=['permno', 'year', 'month'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"   - After merging Market capitalization data, mve valid values: {_monthly['mve'].notna().sum():,}\")\n",
    "else:\n",
    "    print(\"   - mve and bm already exist, skip merge\")\n",
    "\n",
    "# Merge beta and idiovol (aggregated from daily data)\n",
    "if 'beta' not in _monthly.columns or 'idiovol' not in _monthly.columns:\n",
    "    print(\"   - Merge beta and idiovol data...\")\n",
    "    crsp_beta['year'] = crsp_beta['date'].dt.year\n",
    "    crsp_beta['month'] = crsp_beta['date'].dt.month\n",
    "    beta_monthly = crsp_beta.groupby(['permno', 'year', 'month']).last().reset_index()\n",
    "    _monthly = _monthly.merge(\n",
    "        beta_monthly[['permno', 'year', 'month', 'beta', 'betasq', 'idiovol']],\n",
    "        on=['permno', 'year', 'month'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"   - After merging beta data, beta valid values: {_monthly['beta'].notna().sum():,}\")\n",
    "else:\n",
    "    print(\"   - beta and idiovol already exist, skip merge\")\n",
    "\n",
    "# Merge Profitability features (match using year)\n",
    "if 'operprof' not in _monthly.columns or 'roeq' not in _monthly.columns:\n",
    "    if 'compustat_prof_dec' in locals() and len(compustat_prof_dec) > 0:\n",
    "        print(\" - Merge Profitability data...\")\n",
    "        print(f\" - compustat_prof_dec columns: {list(compustat_prof_dec.columns)}\")\n",
    "        \n",
    "        # Check and delete duplicate columns (including those with _x, _y suffixes)\n",
    "        cols_to_drop = []\n",
    "        for col in ['operprof', 'roeq']:\n",
    "            # Check original column names\n",
    "            if col in _monthly.columns:\n",
    "                print(f\" ‚ö†Ô∏è  Found duplicate column {col}ÔºåDelete old column first\")\n",
    "                cols_to_drop.append(col)\n",
    "            # Check columns with suffixes\n",
    "            for suffix in ['_x', '_y', '_new']:\n",
    "                suffixed_col = f'{col}{suffix}'\n",
    "                if suffixed_col in _monthly.columns:\n",
    "                    print(f\" ‚ö†Ô∏è  Found duplicate column {suffixed_col}Ôºådelete first\")\n",
    "                    cols_to_drop.append(suffixed_col)\n",
    "        \n",
    "        if cols_to_drop:\n",
    "            _monthly = _monthly.drop(columns=cols_to_drop)\n",
    "        \n",
    "        # Merge data\n",
    "        _monthly = _monthly.merge(\n",
    "            compustat_prof_dec,\n",
    "            on=['permno', 'year'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Safely check if column exists\n",
    "        if 'operprof' in _monthly.columns:\n",
    "            print(f\" - After merging Profitability data, operprof valid values: {_monthly['operprof'].notna().sum():,}\")\n",
    "        else:\n",
    "            print(\" ‚ö†Ô∏è  operprof column does not exist after merge\")\n",
    "        if 'roeq' in _monthly.columns:\n",
    "            print(f\" - After merging Profitability data, roeq valid values: {_monthly['roeq'].notna().sum():,}\")\n",
    "        else:\n",
    "            print(\" ‚ö†Ô∏è  roeq column does not exist after merge\")\n",
    "    else:\n",
    "        print(\" ‚ö†Ô∏è  compustat_prof_dec does not exist or is empty, skip Profitability data merge\")\n",
    "else:\n",
    "    print(\" - Profitability data already exists, skip merge\")\n",
    "\n",
    "# Merge cashpr (cash price ratio, match using year)\n",
    "if 'cashpr' not in _monthly.columns:\n",
    "    if 'compustat_cash' in locals() and len(compustat_cash) > 0:\n",
    "        print(\"   - Merge cashpr data...\")\n",
    "        compustat_cash_year = compustat_cash[['permno', 'year', 'cashpr']].copy()\n",
    "        _monthly = _monthly.merge(\n",
    "            compustat_cash_year,\n",
    "            on=['permno', 'year'],\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\" - After merging cashpr data, cashpr valid values: {_monthly['cashpr'].notna().sum():,}\")\n",
    "    else:\n",
    "        print(\" - compustat_cash does not exist, skip cashpr merge\")\n",
    "else:\n",
    "    print(\" - cashpr already exists, skip merge\")\n",
    "\n",
    "# Merge Industry codes (need to unify date format)\n",
    "# First clean duplicate sic2 columns (if there are _x, _y suffixes)\n",
    "sic2_cols = [col for col in _monthly.columns if 'sic2' in col]\n",
    "if len(sic2_cols) > 1:\n",
    "    print(f\" - Found duplicate sic2 columns: {sic2_cols}Ôºåcleaning...\")\n",
    "    # Keep the first non-empty sic2 column\n",
    "    for col in sic2_cols:\n",
    "        if col != 'sic2' and _monthly[col].notna().sum() > 0:\n",
    "            if 'sic2' not in _monthly.columns:\n",
    "                _monthly['sic2'] = _monthly[col]\n",
    "            else:\n",
    "                _monthly['sic2'] = _monthly['sic2'].fillna(_monthly[col])\n",
    "    # Delete all columns with suffixes\n",
    "    _monthly = _monthly.drop(columns=[col for col in sic2_cols if col != 'sic2'])\n",
    "\n",
    "if 'sic2' not in _monthly.columns or _monthly['sic2'].isna().all():\n",
    "    if len(crsp_names) > 0:\n",
    "        print(\" - Merge Industry code data...\")\n",
    "        # Ensure crsp_names has sic2 column\n",
    "        if 'sic2' not in crsp_names.columns:\n",
    "            if 'siccd' in crsp_names.columns:\n",
    "                crsp_names['sic2'] = crsp_names['siccd'].astype(str).str[:2]\n",
    "            else:\n",
    "                print(\" ‚ö†Ô∏è  crsp_names does not have siccd or sic2 column\")\n",
    "                crsp_names['sic2'] = None\n",
    "        \n",
    "        crsp_names['year'] = crsp_names['date'].dt.year\n",
    "        crsp_names['month'] = crsp_names['date'].dt.month\n",
    "        \n",
    "        # For each permno-year-month, take the latest sic2 (if there are multiple)\n",
    "        crsp_names_monthly = crsp_names.groupby(['permno', 'year', 'month'])['sic2'].last().reset_index()\n",
    "        \n",
    "        # If _monthly already has sic2 column, delete first (avoid duplicate)\n",
    "        if 'sic2' in _monthly.columns:\n",
    "            _monthly = _monthly.drop(columns=['sic2'])\n",
    "        \n",
    "        _monthly = _monthly.merge(\n",
    "            crsp_names_monthly,\n",
    "            on=['permno', 'year', 'month'],\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"- After merging Industry data, sic2 valid values: {_monthly['sic2'].notna().sum():,}\")\n",
    "    else:\n",
    "        print(\" ‚ö†Ô∏è  crsp_names is empty, skip Industry data merge\")\n",
    "        if 'sic2' not in _monthly.columns:\n",
    "            _monthly['sic2'] = None\n",
    "else:\n",
    "    print(\" - sic2 already exists and has data, skip merge\")\n",
    "\n",
    "# Clean duplicate columns (handle _x, _y suffixes)\n",
    "print(\" - Clean duplicate columns...\")\n",
    "cols_to_drop = []\n",
    "cols_to_rename = {}\n",
    "\n",
    "for col in _monthly.columns:\n",
    "    if col.endswith('_x') or col.endswith('_y'):\n",
    "        base_col = col[:-2]\n",
    "        if base_col in _monthly.columns:\n",
    "            # If base column exists, delete columns with suffixes\n",
    "            cols_to_drop.append(col)\n",
    "        else:\n",
    "            # If base column does not exist, rename to remove suffix\n",
    "            cols_to_rename[col] = base_col\n",
    "\n",
    "# Rename first\n",
    "if cols_to_rename:\n",
    "    _monthly = _monthly.rename(columns=cols_to_rename)\n",
    "    print(f\" - Renamed {len(cols_to_rename)}   columns (remove suffix)\")\n",
    "\n",
    "# Only delete columns that actually exist\n",
    "cols_to_drop = [col for col in cols_to_drop if col in _monthly.columns]\n",
    "if cols_to_drop:\n",
    "    _monthly = _monthly.drop(columns=cols_to_drop)\n",
    "    print(f\" - Deleted {len(cols_to_drop)}   duplicate columns\")\n",
    "else:\n",
    "    print(\" - No duplicate columns to delete\")\n",
    "\n",
    "print(\" ‚úÖ All features merged\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Check current column names...\n",
      "   - Current columns: ['permno', 'date', 'ret_1_0', 'ret_6_1', 'ret_12_1', 'ret_36_1', 'chmom', 'rmax1_21d', 'rvol_21d', 'turnover_126d', 'std_turn', 'dolvol_126d', 'zero_trades_252d', 'bidaskhl_21d', 'me', 'me', 'me', 'be_me', 'be_me', 'be_me', 'beta_60m', 'beta_60m', 'beta_60m', 'betasq', 'betasq', 'ivol_capm_252d', 'ivol_capm_252d', 'ivol_capm_252d', 'year', 'qmj_prof', 'qmj_prof', 'qmj_prof', 'month', 'cashpr', 'sic2', 'roeq']\n",
      "   - Renamed 1  columns\n",
      "   - Final cleanup of duplicate columns...\n",
      "   ‚ö†Ô∏è  Found duplicate column names, cleaning...\n",
      "   - Cleaned 11  duplicate columns\n",
      "   ‚úÖ Variable renaming completed\n",
      "\n",
      "üìä Final data frame shape: (720831, 25)\n",
      "   Column names: ['permno', 'date', 'ret_1_0', 'ret_6_1', 'ret_12_1', 'ret_36_1', 'chmom', 'rmax1_21d', 'rvol_21d', 'turnover_126d', 'std_turn', 'dolvol_126d', 'zero_trades_252d', 'bidaskhl_21d', 'me', 'be_me', 'beta_60m', 'betasq', 'ivol_capm_252d', 'year', 'qmj_prof', 'month', 'cashpr', 'sic2', 'roeq']\n",
      "   Unique column count: 25\n",
      "   - me valid values: 716,975\n",
      "   - be_me valid values: 354,641\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "      <th>ret_1_0</th>\n",
       "      <th>ret_6_1</th>\n",
       "      <th>ret_12_1</th>\n",
       "      <th>ret_36_1</th>\n",
       "      <th>chmom</th>\n",
       "      <th>rmax1_21d</th>\n",
       "      <th>rvol_21d</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>...</th>\n",
       "      <th>be_me</th>\n",
       "      <th>beta_60m</th>\n",
       "      <th>betasq</th>\n",
       "      <th>ivol_capm_252d</th>\n",
       "      <th>year</th>\n",
       "      <th>qmj_prof</th>\n",
       "      <th>month</th>\n",
       "      <th>cashpr</th>\n",
       "      <th>sic2</th>\n",
       "      <th>roeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036752</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>-0.084515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>-0.008108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024013</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>4.257142</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>0.033132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>3.982856</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>0.045195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>3.957697</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       date   ret_1_0  ret_6_1  ret_12_1  ret_36_1  chmom  rmax1_21d  \\\n",
       "0   10026 2018-01-01       NaN      NaN       NaN       NaN    NaN   0.036752   \n",
       "1   10026 2018-02-01 -0.084515      NaN       NaN       NaN    NaN   0.027858   \n",
       "2   10026 2018-03-01 -0.008108      NaN       NaN       NaN    NaN   0.024013   \n",
       "3   10026 2018-04-01  0.033132      NaN       NaN       NaN    NaN   0.023609   \n",
       "4   10026 2018-05-01  0.045195      NaN       NaN       NaN    NaN   0.030120   \n",
       "\n",
       "   rvol_21d  turnover_126d  ...  be_me  beta_60m  betasq  ivol_capm_252d  \\\n",
       "0  0.021137            NaN  ...   <NA>       NaN     NaN             NaN   \n",
       "1  0.020436            NaN  ...   <NA>       NaN     NaN             NaN   \n",
       "2  0.012014       4.257142  ...   <NA>       NaN     NaN             NaN   \n",
       "3  0.011150       3.982856  ...   <NA>       NaN     NaN             NaN   \n",
       "4  0.013237       3.957697  ...   <NA>       NaN     NaN             NaN   \n",
       "\n",
       "   year  qmj_prof  month  cashpr  sic2  roeq  \n",
       "0  2018      <NA>      1    <NA>    20  <NA>  \n",
       "1  2018      <NA>      2    <NA>    20  <NA>  \n",
       "2  2018      <NA>      3    <NA>    20  <NA>  \n",
       "3  2018      <NA>      4    <NA>    20  <NA>  \n",
       "4  2018      <NA>      5    <NA>    20  <NA>  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename to match Project Variable Name\n",
    "# First check and clean duplicate columns, then rename\n",
    "\n",
    "print(\"   - Check current column names...\")\n",
    "print(f\"   - Current columns: {list(_monthly.columns)}\")\n",
    "\n",
    "# Define rename mapping\n",
    "rename_map = {\n",
    "    'mom1m': 'ret_1_0',\n",
    "    'mom6m': 'ret_6_1',\n",
    "    'mom12m': 'ret_12_1',\n",
    "    'mom36m': 'ret_36_1',\n",
    "    'maxret': 'rmax1_21d',\n",
    "    'retvol': 'rvol_21d',\n",
    "    'turn_126d': 'turnover_126d',\n",
    "    'dolvol_126d': 'dolvol_126d',\n",
    "    'zerotrade': 'zero_trades_252d',\n",
    "    'baspread_21d': 'bidaskhl_21d',\n",
    "    'mve': 'me',\n",
    "    'bm': 'be_me',\n",
    "    'beta': 'beta_60m',\n",
    "    'idiovol': 'ivol_capm_252d',\n",
    "    'operprof': 'qmj_prof'\n",
    "}\n",
    "\n",
    "# Only rename existing columns\n",
    "rename_map_filtered = {k: v for k, v in rename_map.items() if k in _monthly.columns}\n",
    "\n",
    "# Check if target column names already exist (may be duplicate columns)\n",
    "for old_col, new_col in rename_map_filtered.items():\n",
    "    if new_col in _monthly.columns and old_col in _monthly.columns:\n",
    "        # If both old and new columns exist, merge data (fill old column nulls with new column)\n",
    "        if old_col != new_col:\n",
    "            print(f\" ‚ö†Ô∏è  {new_col} already exists, merge {old_col}  data...\")\n",
    "            _monthly[new_col] = _monthly[new_col].fillna(_monthly[old_col])\n",
    "            # Delete old column\n",
    "            _monthly = _monthly.drop(columns=[old_col])\n",
    "            # Remove from rename mapping\n",
    "            rename_map_filtered.pop(old_col)\n",
    "\n",
    "# Execute rename\n",
    "if rename_map_filtered:\n",
    "    _monthly = _monthly.rename(columns=rename_map_filtered)\n",
    "    print(f\" - Renamed {len(rename_map_filtered)}   columns\")\n",
    "\n",
    "# Final cleanup: delete all duplicate columns (if any)\n",
    "print(\" - Final cleanup of duplicate columns...\")\n",
    "\n",
    "# Check if there are duplicate column names\n",
    "if len(_monthly.columns) != len(set(_monthly.columns)):\n",
    "    print(\" ‚ö†Ô∏è  Found duplicate column names, cleaning...\")\n",
    "    # Find duplicate column names and their positions\n",
    "    seen = {}\n",
    "    duplicate_info = {}\n",
    "    for i, col in enumerate(_monthly.columns):\n",
    "        if col in seen:\n",
    "            if col not in duplicate_info:\n",
    "                duplicate_info[col] = [seen[col], i]\n",
    "            else:\n",
    "                duplicate_info[col].append(i)\n",
    "        else:\n",
    "            seen[col] = i\n",
    "    \n",
    "    # Merge duplicate column data (fill first column nulls with subsequent columns)\n",
    "    for col_name, indices in duplicate_info.items():\n",
    "        first_idx = indices[0]\n",
    "        # Directly use iloc to access by position, avoid column name duplication issues\n",
    "        first_col_data = _monthly.iloc[:, first_idx].copy()\n",
    "        \n",
    "        for dup_idx in indices[1:]:\n",
    "            dup_col_data = _monthly.iloc[:, dup_idx].copy()\n",
    "            # Fill first column nulls with duplicate column data\n",
    "            mask = first_col_data.isna()\n",
    "            first_col_data.loc[mask] = dup_col_data.loc[mask]\n",
    "        \n",
    "        # Update first column data\n",
    "        _monthly.iloc[:, first_idx] = first_col_data\n",
    "    \n",
    "    # Delete duplicate columns (keep first)\n",
    "    # Use column names to deduplicate, but need to delete by position\n",
    "    cols_to_keep = []\n",
    "    seen_cols = set()\n",
    "    for i, col in enumerate(_monthly.columns):\n",
    "        if col not in seen_cols:\n",
    "            cols_to_keep.append(i)\n",
    "            seen_cols.add(col)\n",
    "    \n",
    "    _monthly = _monthly.iloc[:, cols_to_keep]\n",
    "    print(f\" - Cleaned {sum(len(indices)-1 for indices in duplicate_info.values())}   duplicate columns\")\n",
    "else:\n",
    "    print(\" - No duplicate columns\")\n",
    "\n",
    "print(\" ‚úÖ Variable renaming completed\")\n",
    "print(f\"\\nüìä Final data frame shape: {_monthly.shape}\")\n",
    "print(f\" Column names: {list(_monthly.columns)}\")\n",
    "print(f\" Unique column count: {len(set(_monthly.columns))}\")\n",
    "\n",
    "# Safely check valid values\n",
    "if 'me' in _monthly.columns:\n",
    "    me_count = int(_monthly['me'].notna().sum())\n",
    "    print(f\" - me valid values: {me_count:,}\")\n",
    "else:\n",
    "    print(\" - me column does not exist\")\n",
    "\n",
    "if 'be_me' in _monthly.columns:\n",
    "    be_me_count = int(_monthly['be_me'].notna().sum())\n",
    "    print(f\" - be_me valid values: {be_me_count:,}\")\n",
    "else:\n",
    "    print(\" - be_me column does not exist\")\n",
    "\n",
    "_monthly.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data quality check\n",
    "\n",
    "Check data integrity, missing values, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data quality check:\n",
      "   Total records: 720,831\n",
      "   Number of stocks: 13,854\n",
      "   Date range: 2018-01-01 00:00:00 to 2024-12-01 00:00:00\n",
      "\n",
      "üìä Missing value statistics:\n",
      "                    Missing count  Missing percentage (%)\n",
      "qmj_prof          483552    67.08\n",
      "cashpr            451944    62.70\n",
      "ret_36_1          407173    56.49\n",
      "roeq              379458    52.64\n",
      "be_me             366190    50.80\n",
      "ret_12_1          156730    21.74\n",
      "chmom             156730    21.74\n",
      "ivol_capm_252d    156730    21.74\n",
      "betasq            156730    21.74\n",
      "beta_60m          156730    21.74\n",
      "ret_6_1            99735    13.84\n",
      "zero_trades_252d   71845     9.97\n",
      "dolvol_126d        32653     4.53\n",
      "std_turn           32653     4.53\n",
      "turnover_126d      32653     4.53\n",
      "ret_1_0            13836     1.92\n",
      "me                  3856     0.53\n",
      "bidaskhl_21d        2747     0.38\n",
      "rvol_21d            2747     0.38\n",
      "rmax1_21d           2747     0.38\n",
      "\n",
      "üìä Feature summary:\n",
      "   Total number of : 21\n",
      "   Feature list: ['ret_1_0', 'ret_6_1', 'ret_12_1', 'ret_36_1', 'chmom', 'rmax1_21d', 'rvol_21d', 'turnover_126d', 'std_turn', 'dolvol_126d', 'zero_trades_252d', 'bidaskhl_21d', 'me', 'be_me', 'beta_60m', 'betasq', 'ivol_capm_252d', 'qmj_prof', 'cashpr', 'sic2', 'roeq']\n"
     ]
    }
   ],
   "source": [
    "# Data quality check\n",
    "print(\"üìä Data quality check:\")\n",
    "print(f\" Total records: {len(_monthly):,}\")\n",
    "print(f\" Number of stocks: {_monthly['permno'].nunique():,}\")\n",
    "print(f\" Date range: {_monthly['date'].min()} to {_monthly['date'].max()}\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nüìä Missing value statistics:\")\n",
    "missing_stats = _monthly.isnull().sum()\n",
    "missing_pct = (missing_stats / len(_monthly) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing count': missing_stats,\n",
    "    'Missing percentage (%)': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing count'] > 0].sort_values('Missing count', ascending=False)\n",
    "print(missing_df)\n",
    "\n",
    "# Display feature summary\n",
    "feature_cols = [c for c in _monthly.columns if c not in ['permno', 'date', 'year', 'month']]\n",
    "print(f\"\\nüìä Feature summary:\")\n",
    "print(f\" Total number of : {len(feature_cols)}\")\n",
    "print(f\" Feature list: {feature_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save data\n",
    "\n",
    "Save the extracted  as a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving data to wrds_20_.csv...\n",
      "   ‚úÖ Data savedÔºÅ\n",
      "   - File: wrds_20_.csv\n",
      "   - Number of rows: 720,831\n",
      "   - Number of columns: 25\n",
      "\n",
      "‚úÖ All feature extraction completedÔºÅ\n",
      "\n",
      "üìã List of extracted :\n",
      "    1. ret_1_0\n",
      "    2. ret_6_1\n",
      "    3. ret_12_1\n",
      "    4. ret_36_1\n",
      "    5. chmom\n",
      "    6. rmax1_21d\n",
      "    7. rvol_21d\n",
      "    8. turnover_126d\n",
      "    9. std_turn\n",
      "   10. dolvol_126d\n",
      "   11. zero_trades_252d\n",
      "   12. bidaskhl_21d\n",
      "   13. me\n",
      "   14. be_me\n",
      "   15. beta_60m\n",
      "   16. betasq\n",
      "   17. ivol_capm_252d\n",
      "   18. qmj_prof\n",
      "   19. cashpr\n",
      "   20. sic2\n",
      "   21. roeq\n"
     ]
    }
   ],
   "source": [
    "print(f\"üíæ Saving data to {OUTPUT_FILE}...\")\n",
    "_monthly.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\" ‚úÖ Data savedÔºÅ\")\n",
    "print(f\" - File: {OUTPUT_FILE}\")\n",
    "print(f\" - Number of rows: {len(_monthly):,}\")\n",
    "print(f\" - Number of columns: {len(_monthly.columns)}\")\n",
    "\n",
    "print(\"\\n‚úÖ All feature extraction completedÔºÅ\")\n",
    "print(\"\\nüìã List of extracted :\")\n",
    "feature_cols = [c for c in _monthly.columns if c not in ['permno', 'date', 'year', 'month']]\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
